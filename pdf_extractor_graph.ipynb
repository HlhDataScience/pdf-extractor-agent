{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30306196-59a7-41cf-91dc-620804dcef45",
   "metadata": {},
   "source": [
    "# Testing Notebook for the app different parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d09a5-55bc-40bf-b7f9-20d83a85e338",
   "metadata": {},
   "source": [
    "## 1. Pdf Extractor and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2e944-28de-455e-9d89-814971ac489a",
   "metadata": {},
   "source": [
    "IN this part we created a function that host the pdf extractor part. we tested the function with unitest and after checking it, we created the full function within the PdfExtractor.py and within the test.py file we introduced the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9c8c74-b06c-49d9-a1df-868b93df016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ad7959-8c16-4aa1-9583-35c6225990e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "extractor = PyPDFLoader(file_path=\"2501.00663v1.pdf\")\n",
    "docs = extractor.lazy_load()\n",
    "docs_list = [doc for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f80d5d-e6a1-4fdd-b06f-33149a32adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "for doc in docs_list[:2]:\n",
    "    print(type(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c763e47-46cb-4b98-bd82-9f7c0ce46b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "def pdf_extractor(path_pdf: str, extractor: PyPDFLoader)-> List[Document]:\n",
    "    loader = extractor(file_path= path_pdf)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac304b19-4392-4015-8ccc-185891c203e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Titans: Learning to Memorize at Test Time\n",
      "Ali Behrouz\n",
      "†\n",
      ", Peilin Zhong\n",
      "†\n",
      ", and Vahab Mirrokni\n",
      "†\n",
      "†\n",
      "Google Research\n",
      "{alibehrouz, peilinz, mirrokni}@google.com\n",
      "Abstract\n",
      "Over more than a decade there has been an extensive research effort of how effectively utilize recurrent models and\n",
      "attentions. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows\n",
      "attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling\n",
      "of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new\n",
      "neural long-term memory module that learns to memorize historical context and helps an attention to attend to the\n",
      "current context while utilizing long past information. We show that this neural memory has the advantage of a fast\n",
      "parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its\n",
      "limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its\n",
      "ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce\n",
      "a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate\n",
      "memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics,\n",
      "and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models.\n",
      "They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks\n",
      "compared to baselines.\n",
      "1 Introduction\n",
      "“The true art of memory is the art of attention!\"\n",
      "— Samuel Johnson, 1787\n",
      "T\n",
      "ransformers, pure attention-based architectures (Vaswani et al. 2017), have been firmly established as state-of-\n",
      "the-art models in sequence modeling, mainly due to their in-context learning and ability to learn at scale (Kaplan\n",
      "et al. 2020). The primary building blocks of Transformers–attention modules—function as associative memory\n",
      "blocks (Bietti et al. 2024), where they learn to store key-value associations and retrieve them by computing pairwise\n",
      "similarity between queries (i.e., search signals) and keys (i.e., contexts). Accordingly, by design, the output of a Transformer\n",
      "is exclusively conditioned on the direct dependencies of tokens in the current context window. This accurate modeling of\n",
      "dependencies, however, comes with quadratic time and memory complexity in terms of the context length. In complex\n",
      "real-world tasks (e.g., language modeling (N. F. Liu et al. 2024), video understanding (C.-Y. Wu et al. 2019), long-term time\n",
      "series forecasting (H. Zhou et al. 2021)), the context window can become extremely large, making the applicability of\n",
      "Transformers challenging in these downstream tasks.\n",
      "To overcome the scalability issue of Transformers, recent studies aim to design different variants of linear Transform-\n",
      "ers (Kacham, Mirrokni, and P. Zhong 2024; Katharopoulos et al. 2020; S. Yang, B. Wang, Shen, et al. 2024), where softmax is\n",
      "replaced by a kernel function in the attention (see §2.1 for details), resulting in a significant drop in memory consumption.\n",
      "Despite efficiency and the ability to scale to longer context, linear Transformers do not show competitive performance\n",
      "compared to Transformers as the kernel trick makes the model a linear recurrent network, in which the data is compressed\n",
      "into a matrix-valued states (Katharopoulos et al. 2020). This, however, brings a contradictory fact about linear recurrent (or\n",
      "linear Transformers) models: On one hand, we use these linear models to enhance scalability and efficiency (linear vs.\n",
      "quadratic complexity), whose advantages is appeared for very long context; On the other hand, a very long context cannot\n",
      "be properly compressed in a small vector-valued or matrix-valued states (S. Wang 2024).\n",
      "1\n",
      "arXiv:2501.00663v1  [cs.LG]  31 Dec 2024' metadata={'source': '2501.00663v1.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "docs = pdf_extractor(path_pdf=\"2501.00663v1.pdf\", extractor=PyPDFLoader)\n",
    "for doc in docs[:1]:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd771ef9-3d11-4bee-bffb-bf16b3f22dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "class TestPDFExtractor(unittest.TestCase):\n",
    "    def test_pdf_extractor(self):\n",
    "        # Arrange\n",
    "        mock_path = \"sample.pdf\"\n",
    "        mock_content = \"This is a test document.\"\n",
    "        \n",
    "        # Create a mock PyPDFLoader\n",
    "        mock_loader = MagicMock(spec=PyPDFLoader)\n",
    "        mock_loader_instance = MagicMock()\n",
    "        mock_loader.return_value = mock_loader_instance\n",
    "        \n",
    "        # Mock the loader's load method\n",
    "        mock_doc = Document(page_content=mock_content)\n",
    "        mock_loader_instance.load.return_value = [mock_doc]\n",
    "        \n",
    "        # Act\n",
    "        result = pdf_extractor(path_pdf=mock_path, extractor=mock_loader)\n",
    "        \n",
    "        # Assert\n",
    "        self.assertIsInstance(result, list, \"Result should be a list.\")\n",
    "        self.assertGreater(len(result), 0, \"Result list should not be empty.\")\n",
    "        self.assertIsInstance(result[0], Document, \"Result should contain Document objects.\")\n",
    "        self.assertEqual(result[0].page_content, mock_content, \"Document content should match expected content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33afb56-6b9f-4770-82fe-87d75f81f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestPDFExtractor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae3f69-74c8-426d-9104-cd92c7142d4d",
   "metadata": {},
   "source": [
    "## LLM model and test for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e24aab0-dbc0-457a-8cfa-58e822964b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ANTHROPIC_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810b87f-6042-4500-9007-0744503d86e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97538a-6a8f-43b3-9648-96dbdcbf6d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab277be-d557-4190-b816-f609d9ee6c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
